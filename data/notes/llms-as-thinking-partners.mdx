---
title: LLMs as thinking partners
date: '2026-02-28'
summary: Using language models not for answers but for the process of thinking.
tags: ['AI', 'tools']
---

The most useful thing about LLMs isn't that they give you answers. It's that they give you *structured resistance* â€” a conversational surface to push against while working through a problem.

The best interactions feel less like querying a database and more like thinking out loud to someone who asks good follow-up questions. You say something half-formed, the model reflects it back with more structure, you correct the structure, and in doing so you discover what you actually meant.

This is what good interlocutors do. The model is a very good interlocutor, even if it sometimes confabulates.

The limitation is that it has no stakes. It won't push back hard because it doesn't care if you're wrong. For that, you still need people who will tell you uncomfortable things.
